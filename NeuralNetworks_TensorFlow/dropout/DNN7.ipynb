{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>  Deep Neural Network (DNN) using plain TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'blue'> Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/usr/local/lib/python3.5/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "X_16_val                  -> array([[-0.05248989,  0.95262376, -0.95081096, ...\n",
      "X_32_val                  -> array([[-0.26412427,  0.80742202,  0.90784197, ...\n",
      "X_32test_std              -> defaultdict(<class 'list'>, {0: array([[-0.2641242\n",
      "X_32train_std             -> array([[-0.71199092,  0.15545522, -0.78672279, ...\n",
      "X_test                    -> defaultdict(<class 'list'>, {0: array([[[ 0.003087\n",
      "X_test_std                -> defaultdict(<class 'list'>, {0: array([[ -5.248988\n",
      "X_train                   -> array([[[ -8.82267195e-04,   4.11425252e-03,  -7.3\n",
      "X_train_std               -> array([[-0.71199092,  0.15545522, -0.78672279, ...\n",
      "snrs                      -> [-20, -18, -16, -14, -12, -10, -8, -6, -4, -2, 0, \n",
      "y_16_val                  -> array([7, 6, 5, ..., 1, 4, 7])\n",
      "y_32_test                 -> defaultdict(<class 'list'>, {0: array([4, 6, 6, ..\n",
      "y_32_train                -> array([4, 2, 0, ..., 1, 4, 6])\n",
      "y_32_val                  -> array([4, 6, 6, ..., 6, 7, 3])\n",
      "y_test                    -> defaultdict(<class 'list'>, {0: array([7, 6, 5, ..\n",
      "y_train                   -> array([4, 2, 0, ..., 1, 4, 6])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import defaultdict\n",
    "from time import time\n",
    "\n",
    "%store -r\n",
    "%store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:  (80000, 32) and labels:  (80000,)\n",
      " \n",
      "Test data:\n",
      "Total 20 (4000, 32) arrays for SNR values:\n",
      "[-20, -18, -16, -14, -12, -10, -8, -6, -4, -2, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data: \", X_32train_std.shape, \"and labels: \", y_32_train.shape)\n",
    "print(\" \")\n",
    "print(\"Test data:\")\n",
    "print(\"Total\", len(X_32test_std), X_32test_std[18].shape, \"arrays for SNR values:\")\n",
    "print(sorted(X_32test_std.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'blue'> Design and train the DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 1.621086\tMinimum loss: 1.621086\tAccuracy on validation set: 0.36\n",
      "1\tValidation loss: 1.523906\tMinimum loss: 1.523906\tAccuracy on validation set: 0.40\n",
      "2\tValidation loss: 1.476788\tMinimum loss: 1.476788\tAccuracy on validation set: 0.42\n",
      "3\tValidation loss: 1.448623\tMinimum loss: 1.448623\tAccuracy on validation set: 0.43\n",
      "4\tValidation loss: 1.430523\tMinimum loss: 1.430523\tAccuracy on validation set: 0.44\n",
      "5\tValidation loss: 1.418511\tMinimum loss: 1.418511\tAccuracy on validation set: 0.44\n",
      "6\tValidation loss: 1.408828\tMinimum loss: 1.408828\tAccuracy on validation set: 0.45\n",
      "7\tValidation loss: 1.401278\tMinimum loss: 1.401278\tAccuracy on validation set: 0.45\n",
      "8\tValidation loss: 1.392309\tMinimum loss: 1.392309\tAccuracy on validation set: 0.46\n",
      "9\tValidation loss: 1.386516\tMinimum loss: 1.386516\tAccuracy on validation set: 0.46\n",
      "10\tValidation loss: 1.379810\tMinimum loss: 1.379810\tAccuracy on validation set: 0.46\n",
      "11\tValidation loss: 1.375402\tMinimum loss: 1.375402\tAccuracy on validation set: 0.47\n",
      "12\tValidation loss: 1.371645\tMinimum loss: 1.371645\tAccuracy on validation set: 0.46\n",
      "13\tValidation loss: 1.365954\tMinimum loss: 1.365954\tAccuracy on validation set: 0.47\n",
      "14\tValidation loss: 1.352511\tMinimum loss: 1.352511\tAccuracy on validation set: 0.47\n",
      "15\tValidation loss: 1.343984\tMinimum loss: 1.343984\tAccuracy on validation set: 0.48\n",
      "16\tValidation loss: 1.338249\tMinimum loss: 1.338249\tAccuracy on validation set: 0.48\n",
      "17\tValidation loss: 1.330381\tMinimum loss: 1.330381\tAccuracy on validation set: 0.48\n",
      "18\tValidation loss: 1.317997\tMinimum loss: 1.317997\tAccuracy on validation set: 0.49\n",
      "19\tValidation loss: 1.321270\tMinimum loss: 1.317997\tAccuracy on validation set: 0.49\n",
      "20\tValidation loss: 1.311588\tMinimum loss: 1.311588\tAccuracy on validation set: 0.49\n",
      "21\tValidation loss: 1.307566\tMinimum loss: 1.307566\tAccuracy on validation set: 0.50\n",
      "22\tValidation loss: 1.301891\tMinimum loss: 1.301891\tAccuracy on validation set: 0.50\n",
      "23\tValidation loss: 1.300510\tMinimum loss: 1.300510\tAccuracy on validation set: 0.50\n",
      "24\tValidation loss: 1.295297\tMinimum loss: 1.295297\tAccuracy on validation set: 0.50\n",
      "25\tValidation loss: 1.297458\tMinimum loss: 1.295297\tAccuracy on validation set: 0.50\n",
      "26\tValidation loss: 1.293749\tMinimum loss: 1.293749\tAccuracy on validation set: 0.50\n",
      "27\tValidation loss: 1.296218\tMinimum loss: 1.293749\tAccuracy on validation set: 0.50\n",
      "28\tValidation loss: 1.294716\tMinimum loss: 1.293749\tAccuracy on validation set: 0.50\n",
      "29\tValidation loss: 1.288917\tMinimum loss: 1.288917\tAccuracy on validation set: 0.50\n",
      "30\tValidation loss: 1.288582\tMinimum loss: 1.288582\tAccuracy on validation set: 0.50\n",
      "31\tValidation loss: 1.290878\tMinimum loss: 1.288582\tAccuracy on validation set: 0.50\n",
      "32\tValidation loss: 1.285512\tMinimum loss: 1.285512\tAccuracy on validation set: 0.51\n",
      "33\tValidation loss: 1.283488\tMinimum loss: 1.283488\tAccuracy on validation set: 0.50\n",
      "34\tValidation loss: 1.283595\tMinimum loss: 1.283488\tAccuracy on validation set: 0.51\n",
      "35\tValidation loss: 1.284249\tMinimum loss: 1.283488\tAccuracy on validation set: 0.51\n",
      "36\tValidation loss: 1.282458\tMinimum loss: 1.282458\tAccuracy on validation set: 0.51\n",
      "37\tValidation loss: 1.280599\tMinimum loss: 1.280599\tAccuracy on validation set: 0.51\n",
      "38\tValidation loss: 1.277841\tMinimum loss: 1.277841\tAccuracy on validation set: 0.51\n",
      "39\tValidation loss: 1.279401\tMinimum loss: 1.277841\tAccuracy on validation set: 0.51\n",
      "40\tValidation loss: 1.276890\tMinimum loss: 1.276890\tAccuracy on validation set: 0.51\n",
      "41\tValidation loss: 1.284378\tMinimum loss: 1.276890\tAccuracy on validation set: 0.51\n",
      "42\tValidation loss: 1.275016\tMinimum loss: 1.275016\tAccuracy on validation set: 0.51\n",
      "43\tValidation loss: 1.275445\tMinimum loss: 1.275016\tAccuracy on validation set: 0.51\n",
      "44\tValidation loss: 1.277473\tMinimum loss: 1.275016\tAccuracy on validation set: 0.51\n",
      "45\tValidation loss: 1.275743\tMinimum loss: 1.275016\tAccuracy on validation set: 0.51\n",
      "46\tValidation loss: 1.276542\tMinimum loss: 1.275016\tAccuracy on validation set: 0.51\n",
      "47\tValidation loss: 1.273965\tMinimum loss: 1.273965\tAccuracy on validation set: 0.51\n",
      "48\tValidation loss: 1.275459\tMinimum loss: 1.273965\tAccuracy on validation set: 0.51\n",
      "49\tValidation loss: 1.271597\tMinimum loss: 1.271597\tAccuracy on validation set: 0.51\n",
      "50\tValidation loss: 1.275361\tMinimum loss: 1.271597\tAccuracy on validation set: 0.51\n",
      "51\tValidation loss: 1.273464\tMinimum loss: 1.271597\tAccuracy on validation set: 0.51\n",
      "52\tValidation loss: 1.276512\tMinimum loss: 1.271597\tAccuracy on validation set: 0.51\n",
      "53\tValidation loss: 1.273876\tMinimum loss: 1.271597\tAccuracy on validation set: 0.51\n",
      "54\tValidation loss: 1.273736\tMinimum loss: 1.271597\tAccuracy on validation set: 0.51\n",
      "55\tValidation loss: 1.272442\tMinimum loss: 1.271597\tAccuracy on validation set: 0.51\n",
      "56\tValidation loss: 1.273882\tMinimum loss: 1.271597\tAccuracy on validation set: 0.51\n",
      "57\tValidation loss: 1.271712\tMinimum loss: 1.271597\tAccuracy on validation set: 0.51\n",
      "58\tValidation loss: 1.270913\tMinimum loss: 1.270913\tAccuracy on validation set: 0.51\n",
      "59\tValidation loss: 1.275193\tMinimum loss: 1.270913\tAccuracy on validation set: 0.51\n",
      "60\tValidation loss: 1.273337\tMinimum loss: 1.270913\tAccuracy on validation set: 0.51\n",
      "61\tValidation loss: 1.274853\tMinimum loss: 1.270913\tAccuracy on validation set: 0.51\n",
      "62\tValidation loss: 1.272360\tMinimum loss: 1.270913\tAccuracy on validation set: 0.51\n",
      "63\tValidation loss: 1.271765\tMinimum loss: 1.270913\tAccuracy on validation set: 0.51\n",
      "64\tValidation loss: 1.271658\tMinimum loss: 1.270913\tAccuracy on validation set: 0.51\n",
      "65\tValidation loss: 1.269456\tMinimum loss: 1.269456\tAccuracy on validation set: 0.51\n",
      "66\tValidation loss: 1.273422\tMinimum loss: 1.269456\tAccuracy on validation set: 0.51\n",
      "67\tValidation loss: 1.276062\tMinimum loss: 1.269456\tAccuracy on validation set: 0.51\n",
      "68\tValidation loss: 1.272854\tMinimum loss: 1.269456\tAccuracy on validation set: 0.51\n",
      "69\tValidation loss: 1.272436\tMinimum loss: 1.269456\tAccuracy on validation set: 0.51\n",
      "70\tValidation loss: 1.268843\tMinimum loss: 1.268843\tAccuracy on validation set: 0.51\n",
      "71\tValidation loss: 1.271024\tMinimum loss: 1.268843\tAccuracy on validation set: 0.51\n",
      "72\tValidation loss: 1.271343\tMinimum loss: 1.268843\tAccuracy on validation set: 0.51\n",
      "73\tValidation loss: 1.271526\tMinimum loss: 1.268843\tAccuracy on validation set: 0.51\n",
      "74\tValidation loss: 1.271895\tMinimum loss: 1.268843\tAccuracy on validation set: 0.51\n",
      "75\tValidation loss: 1.273278\tMinimum loss: 1.268843\tAccuracy on validation set: 0.51\n",
      "76\tValidation loss: 1.272517\tMinimum loss: 1.268843\tAccuracy on validation set: 0.51\n",
      "77\tValidation loss: 1.265603\tMinimum loss: 1.265603\tAccuracy on validation set: 0.51\n",
      "78\tValidation loss: 1.272897\tMinimum loss: 1.265603\tAccuracy on validation set: 0.51\n",
      "79\tValidation loss: 1.271242\tMinimum loss: 1.265603\tAccuracy on validation set: 0.51\n",
      "80\tValidation loss: 1.267643\tMinimum loss: 1.265603\tAccuracy on validation set: 0.51\n",
      "81\tValidation loss: 1.271992\tMinimum loss: 1.265603\tAccuracy on validation set: 0.51\n",
      "82\tValidation loss: 1.269614\tMinimum loss: 1.265603\tAccuracy on validation set: 0.51\n",
      "83\tValidation loss: 1.268880\tMinimum loss: 1.265603\tAccuracy on validation set: 0.51\n",
      "84\tValidation loss: 1.272371\tMinimum loss: 1.265603\tAccuracy on validation set: 0.51\n",
      "85\tValidation loss: 1.272786\tMinimum loss: 1.265603\tAccuracy on validation set: 0.51\n",
      "86\tValidation loss: 1.269266\tMinimum loss: 1.265603\tAccuracy on validation set: 0.51\n",
      "87\tValidation loss: 1.272610\tMinimum loss: 1.265603\tAccuracy on validation set: 0.51\n",
      "88\tValidation loss: 1.270541\tMinimum loss: 1.265603\tAccuracy on validation set: 0.51\n",
      "89\tValidation loss: 1.273280\tMinimum loss: 1.265603\tAccuracy on validation set: 0.51\n",
      "90\tValidation loss: 1.271335\tMinimum loss: 1.265603\tAccuracy on validation set: 0.51\n",
      "91\tValidation loss: 1.268129\tMinimum loss: 1.265603\tAccuracy on validation set: 0.51\n",
      "92\tValidation loss: 1.271277\tMinimum loss: 1.265603\tAccuracy on validation set: 0.51\n",
      "93\tValidation loss: 1.271536\tMinimum loss: 1.265603\tAccuracy on validation set: 0.51\n",
      "94\tValidation loss: 1.273330\tMinimum loss: 1.265603\tAccuracy on validation set: 0.51\n",
      "95\tValidation loss: 1.271661\tMinimum loss: 1.265603\tAccuracy on validation set: 0.51\n",
      "96\tValidation loss: 1.271208\tMinimum loss: 1.265603\tAccuracy on validation set: 0.51\n",
      "97\tValidation loss: 1.274234\tMinimum loss: 1.265603\tAccuracy on validation set: 0.51\n",
      "** EARLY STOPPING ** \n",
      " \n",
      "INFO:tensorflow:Restoring parameters from ./DNNdropout1.ckpt\n",
      "Training and testing took 3.117459 minutes\n"
     ]
    }
   ],
   "source": [
    "# ----------------- Initialize parameters -----------------------\n",
    "\n",
    "\n",
    "n_hidden1 = 256\n",
    "n_hidden2 = 256\n",
    "n_outputs = 8\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, 32))\n",
    "\n",
    "y = tf.placeholder(tf.int64, shape=(None))\n",
    "\n",
    "# ------------------- Define layers -----------------------\n",
    "\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "\n",
    "def layer(X, n_neurons, activation):\n",
    "    layer = fully_connected(X, n_neurons, activation_fn = activation, \n",
    "                            weights_initializer = tf.contrib.layers.xavier_initializer())\n",
    "    dropout_layer = tf.layers.dropout(layer, rate = 0.2, training = True)\n",
    "    return dropout_layer\n",
    "\n",
    "layer1 = layer(X, n_hidden1, activation = tf.nn.relu)\n",
    "\n",
    "layer2 = layer(layer1, n_hidden2, activation = tf.nn.relu)\n",
    "\n",
    "logits = fully_connected(layer2, n_outputs, activation_fn = None, weights_initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "# ----------------- Specify performance measure ----------------------\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        \n",
    "# ------------------ Execution phase ----------------------------------    \n",
    "\n",
    "n_epochs = 1000\n",
    "batch_size = 1024\n",
    "n_train = X_train_std.shape[0]\n",
    "n_iter = n_train//batch_size\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "min_loss = np.infty\n",
    "epochs_without_improvement = 0 \n",
    "max_epochs_without_improvement = 20   \n",
    "\n",
    "acc_test = defaultdict(list)\n",
    "\n",
    "start = time()\n",
    "path = \"./DNNdropout1.ckpt\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(n_iter):\n",
    "            rand_indices = np.random.choice(n_train,batch_size) #select random samples to form mini batches   \n",
    "            X_batch, y_batch = X_32train_std[rand_indices], y_32_train[rand_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        valid_loss, acc_val = sess.run([loss, accuracy], feed_dict={X: X_32_val, y: y_32_val})\n",
    "        \n",
    "        # Early stopping \n",
    "        \n",
    "        if valid_loss < min_loss:\n",
    "            save_path = saver.save(sess, path)\n",
    "            min_loss = valid_loss\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement > max_epochs_without_improvement:\n",
    "                print(\"** EARLY STOPPING ** \")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tMinimum loss: {:.6f}\\tAccuracy on validation set: {:.2f}\".format(\n",
    "            epoch, valid_loss, min_loss, acc_val))\n",
    "\n",
    "print(\" \")\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, path)\n",
    "    for snr in snrs:\n",
    "        acc_test[snr] = accuracy.eval(feed_dict={X: X_32test_std[snr], y: y_32_test[snr]})\n",
    "\n",
    "print(\"Training and testing took %f minutes\"%(float(time() - start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'blue'> Test the DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN's test accuracy on -20 dB SNR samples =  0.127\n",
      "DNN's test accuracy on -18 dB SNR samples =  0.125\n",
      "DNN's test accuracy on -16 dB SNR samples =  0.1315\n",
      "DNN's test accuracy on -14 dB SNR samples =  0.1285\n",
      "DNN's test accuracy on -12 dB SNR samples =  0.14725\n",
      "DNN's test accuracy on -10 dB SNR samples =  0.1865\n",
      "DNN's test accuracy on -8 dB SNR samples =  0.271\n",
      "DNN's test accuracy on -6 dB SNR samples =  0.3505\n",
      "DNN's test accuracy on -4 dB SNR samples =  0.41175\n",
      "DNN's test accuracy on -2 dB SNR samples =  0.47875\n",
      "DNN's test accuracy on 0 dB SNR samples =  0.554\n",
      "DNN's test accuracy on 2 dB SNR samples =  0.67375\n",
      "DNN's test accuracy on 4 dB SNR samples =  0.8015\n",
      "DNN's test accuracy on 6 dB SNR samples =  0.819\n",
      "DNN's test accuracy on 8 dB SNR samples =  0.82425\n",
      "DNN's test accuracy on 10 dB SNR samples =  0.8375\n",
      "DNN's test accuracy on 12 dB SNR samples =  0.8375\n",
      "DNN's test accuracy on 14 dB SNR samples =  0.835\n",
      "DNN's test accuracy on 16 dB SNR samples =  0.82125\n",
      "DNN's test accuracy on 18 dB SNR samples =  0.83275\n"
     ]
    }
   ],
   "source": [
    "for snr in snrs:\n",
    "    print(\"DNN's test accuracy on %d dB SNR samples = \"%(snr), acc_test[snr])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <font color = 'blue'> Visualize DNN's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('classic')\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4), dpi=100)\n",
    "x = snrs\n",
    "y = list(acc_test.values())\n",
    "plt.plot(x, y, marker=\"o\", linewidth=2.0, linestyle='dashed', color='royalblue')\n",
    "plt.axis([-20, 20, 0, 1])\n",
    "plt.xticks(np.arange(min(x), max(x)+1, 2.0))\n",
    "plt.yticks(np.arange(0, 1, 0.10))\n",
    "\n",
    "ttl = plt.title('SNR vs Accuracy', fontsize=16)\n",
    "ttl.set_weight('bold')\n",
    "plt.xlabel('SNR (dB)', fontsize=14)\n",
    "plt.ylabel('Test accuracy', fontsize=14)\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {-20: 0.127,\n",
       "             -18: 0.125,\n",
       "             -16: 0.13150001,\n",
       "             -14: 0.1285,\n",
       "             -12: 0.14725,\n",
       "             -10: 0.1865,\n",
       "             -8: 0.271,\n",
       "             -6: 0.35049999,\n",
       "             -4: 0.41174999,\n",
       "             -2: 0.47874999,\n",
       "             0: 0.55400002,\n",
       "             2: 0.67374998,\n",
       "             4: 0.80150002,\n",
       "             6: 0.81900001,\n",
       "             8: 0.82424998,\n",
       "             10: 0.83749998,\n",
       "             12: 0.83749998,\n",
       "             14: 0.83499998,\n",
       "             16: 0.82125002,\n",
       "             18: 0.83275002})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
