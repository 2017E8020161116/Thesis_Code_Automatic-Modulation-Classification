{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>  Deep Neural Network (DNN) using plain TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'blue'> Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "X_16_val                  -> array([[-0.05248989,  0.95262376, -0.95081096, ...\n",
      "X_32_val                  -> array([[-0.26412427,  0.80742202,  0.90784197, ...\n",
      "X_32test_std              -> defaultdict(<class 'list'>, {0: array([[-0.2641242\n",
      "X_32train_std             -> array([[-0.71199092,  0.15545522, -0.78672279, ...\n",
      "X_test                    -> defaultdict(<class 'list'>, {0: array([[[ 0.003087\n",
      "X_test_std                -> defaultdict(<class 'list'>, {0: array([[ -5.248988\n",
      "X_train                   -> array([[[ -8.82267195e-04,   4.11425252e-03,  -7.3\n",
      "X_train_std               -> array([[-0.71199092,  0.15545522, -0.78672279, ...\n",
      "snrs                      -> [-20, -18, -16, -14, -12, -10, -8, -6, -4, -2, 0, \n",
      "y_16_val                  -> array([7, 6, 5, ..., 1, 4, 7])\n",
      "y_32_test                 -> defaultdict(<class 'list'>, {0: array([4, 6, 6, ..\n",
      "y_32_train                -> array([4, 2, 0, ..., 1, 4, 6])\n",
      "y_32_val                  -> array([4, 6, 6, ..., 6, 7, 3])\n",
      "y_test                    -> defaultdict(<class 'list'>, {0: array([7, 6, 5, ..\n",
      "y_train                   -> array([4, 2, 0, ..., 1, 4, 6])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import defaultdict\n",
    "from time import time\n",
    "\n",
    "%store -r\n",
    "%store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:  (80000, 32) and labels:  (80000,)\n",
      " \n",
      "Test data:\n",
      "Total 20 (4000, 32) arrays for SNR values:\n",
      "[-20, -18, -16, -14, -12, -10, -8, -6, -4, -2, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data: \", X_32train_std.shape, \"and labels: \", y_32_train.shape)\n",
    "print(\" \")\n",
    "print(\"Test data:\")\n",
    "print(\"Total\", len(X_32test_std), X_32test_std[18].shape, \"arrays for SNR values:\")\n",
    "print(sorted(X_32test_std.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'blue'> Design and train the DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 1.400941\tMinimum loss: 1.400941\tAccuracy on validation set: 0.43\n",
      "1\tValidation loss: 1.328522\tMinimum loss: 1.328522\tAccuracy on validation set: 0.45\n",
      "2\tValidation loss: 1.305086\tMinimum loss: 1.305086\tAccuracy on validation set: 0.46\n",
      "3\tValidation loss: 1.293743\tMinimum loss: 1.293743\tAccuracy on validation set: 0.46\n",
      "4\tValidation loss: 1.277900\tMinimum loss: 1.277900\tAccuracy on validation set: 0.47\n",
      "5\tValidation loss: 1.260594\tMinimum loss: 1.260594\tAccuracy on validation set: 0.48\n",
      "6\tValidation loss: 1.244187\tMinimum loss: 1.244187\tAccuracy on validation set: 0.49\n",
      "7\tValidation loss: 1.226691\tMinimum loss: 1.226691\tAccuracy on validation set: 0.49\n",
      "8\tValidation loss: 1.215651\tMinimum loss: 1.215651\tAccuracy on validation set: 0.50\n",
      "9\tValidation loss: 1.204782\tMinimum loss: 1.204782\tAccuracy on validation set: 0.50\n",
      "10\tValidation loss: 1.193974\tMinimum loss: 1.193974\tAccuracy on validation set: 0.50\n",
      "11\tValidation loss: 1.192578\tMinimum loss: 1.192578\tAccuracy on validation set: 0.50\n",
      "12\tValidation loss: 1.186512\tMinimum loss: 1.186512\tAccuracy on validation set: 0.51\n",
      "13\tValidation loss: 1.181017\tMinimum loss: 1.181017\tAccuracy on validation set: 0.51\n",
      "14\tValidation loss: 1.180277\tMinimum loss: 1.180277\tAccuracy on validation set: 0.51\n",
      "15\tValidation loss: 1.175968\tMinimum loss: 1.175968\tAccuracy on validation set: 0.51\n",
      "16\tValidation loss: 1.176109\tMinimum loss: 1.175968\tAccuracy on validation set: 0.51\n",
      "17\tValidation loss: 1.173930\tMinimum loss: 1.173930\tAccuracy on validation set: 0.51\n",
      "18\tValidation loss: 1.173132\tMinimum loss: 1.173132\tAccuracy on validation set: 0.51\n",
      "19\tValidation loss: 1.172799\tMinimum loss: 1.172799\tAccuracy on validation set: 0.51\n",
      "20\tValidation loss: 1.172720\tMinimum loss: 1.172720\tAccuracy on validation set: 0.51\n",
      "21\tValidation loss: 1.176250\tMinimum loss: 1.172720\tAccuracy on validation set: 0.51\n",
      "22\tValidation loss: 1.170807\tMinimum loss: 1.170807\tAccuracy on validation set: 0.51\n",
      "23\tValidation loss: 1.170736\tMinimum loss: 1.170736\tAccuracy on validation set: 0.51\n",
      "24\tValidation loss: 1.167929\tMinimum loss: 1.167929\tAccuracy on validation set: 0.51\n",
      "25\tValidation loss: 1.171379\tMinimum loss: 1.167929\tAccuracy on validation set: 0.51\n",
      "26\tValidation loss: 1.167526\tMinimum loss: 1.167526\tAccuracy on validation set: 0.51\n",
      "27\tValidation loss: 1.168470\tMinimum loss: 1.167526\tAccuracy on validation set: 0.51\n",
      "28\tValidation loss: 1.175529\tMinimum loss: 1.167526\tAccuracy on validation set: 0.51\n",
      "29\tValidation loss: 1.169599\tMinimum loss: 1.167526\tAccuracy on validation set: 0.51\n",
      "30\tValidation loss: 1.171174\tMinimum loss: 1.167526\tAccuracy on validation set: 0.51\n",
      "31\tValidation loss: 1.171751\tMinimum loss: 1.167526\tAccuracy on validation set: 0.51\n",
      "32\tValidation loss: 1.171742\tMinimum loss: 1.167526\tAccuracy on validation set: 0.51\n",
      "33\tValidation loss: 1.173022\tMinimum loss: 1.167526\tAccuracy on validation set: 0.51\n",
      "34\tValidation loss: 1.173047\tMinimum loss: 1.167526\tAccuracy on validation set: 0.51\n",
      "35\tValidation loss: 1.176643\tMinimum loss: 1.167526\tAccuracy on validation set: 0.51\n",
      "36\tValidation loss: 1.173282\tMinimum loss: 1.167526\tAccuracy on validation set: 0.51\n",
      "37\tValidation loss: 1.174996\tMinimum loss: 1.167526\tAccuracy on validation set: 0.51\n",
      "38\tValidation loss: 1.179861\tMinimum loss: 1.167526\tAccuracy on validation set: 0.51\n",
      "39\tValidation loss: 1.178405\tMinimum loss: 1.167526\tAccuracy on validation set: 0.51\n",
      "40\tValidation loss: 1.177645\tMinimum loss: 1.167526\tAccuracy on validation set: 0.51\n",
      "41\tValidation loss: 1.175749\tMinimum loss: 1.167526\tAccuracy on validation set: 0.51\n",
      "42\tValidation loss: 1.180226\tMinimum loss: 1.167526\tAccuracy on validation set: 0.51\n",
      "43\tValidation loss: 1.178823\tMinimum loss: 1.167526\tAccuracy on validation set: 0.51\n",
      "44\tValidation loss: 1.182485\tMinimum loss: 1.167526\tAccuracy on validation set: 0.51\n",
      "45\tValidation loss: 1.182699\tMinimum loss: 1.167526\tAccuracy on validation set: 0.51\n",
      "46\tValidation loss: 1.184240\tMinimum loss: 1.167526\tAccuracy on validation set: 0.51\n",
      "** EARLY STOPPING ** \n",
      " \n",
      "INFO:tensorflow:Restoring parameters from ./DNNdropout7.ckpt\n",
      "Training and testing took 6.731777 minutes\n"
     ]
    }
   ],
   "source": [
    "# ----------------- Initialize parameters -----------------------\n",
    "\n",
    "\n",
    "n_hidden1 = 1024\n",
    "n_hidden2 = 1024\n",
    "n_outputs = 8\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, 32))\n",
    "\n",
    "y = tf.placeholder(tf.int64, shape=(None))\n",
    "\n",
    "# ------------------- Define layers -----------------------\n",
    "\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "\n",
    "def layer(X, n_neurons, activation):\n",
    "    layer = fully_connected(X, n_neurons, activation_fn = activation, \n",
    "                            weights_initializer = tf.contrib.layers.xavier_initializer())\n",
    "    dropout_layer = tf.layers.dropout(layer, rate = 0.3, training = True)\n",
    "    return dropout_layer\n",
    "\n",
    "layer1 = layer(X, n_hidden1, activation = tf.nn.relu)\n",
    "\n",
    "layer2 = layer(layer1, n_hidden2, activation = tf.nn.relu)\n",
    "\n",
    "logits = fully_connected(layer2, n_outputs, activation_fn = None, weights_initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "# ----------------- Specify performance measure ----------------------\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        \n",
    "# ------------------ Execution phase ----------------------------------    \n",
    "\n",
    "n_epochs = 1000\n",
    "batch_size = 1024\n",
    "n_train = X_train_std.shape[0]\n",
    "n_iter = n_train//batch_size\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "min_loss = np.infty\n",
    "epochs_without_improvement = 0 \n",
    "max_epochs_without_improvement = 20   \n",
    "\n",
    "acc_test = defaultdict(list)\n",
    "\n",
    "start = time()\n",
    "path = \"./DNNdropout7.ckpt\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(n_iter):\n",
    "            rand_indices = np.random.choice(n_train,batch_size) #select random samples to form mini batches   \n",
    "            X_batch, y_batch = X_32train_std[rand_indices], y_32_train[rand_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        valid_loss, acc_val = sess.run([loss, accuracy], feed_dict={X: X_32_val, y: y_32_val})\n",
    "        \n",
    "        # Early stopping \n",
    "        \n",
    "        if valid_loss < min_loss:\n",
    "            save_path = saver.save(sess, path)\n",
    "            min_loss = valid_loss\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement > max_epochs_without_improvement:\n",
    "                print(\"** EARLY STOPPING ** \")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tMinimum loss: {:.6f}\\tAccuracy on validation set: {:.2f}\".format(\n",
    "            epoch, valid_loss, min_loss, acc_val))\n",
    "\n",
    "print(\" \")\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, path)\n",
    "    for snr in snrs:\n",
    "        acc_test[snr] = accuracy.eval(feed_dict={X: X_32test_std[snr], y: y_32_test[snr]})\n",
    "\n",
    "print(\"Training and testing took %f minutes\"%(float(time() - start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'blue'> Test the DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN's test accuracy on -20 dB SNR samples =  0.127\n",
      "DNN's test accuracy on -18 dB SNR samples =  0.12675\n",
      "DNN's test accuracy on -16 dB SNR samples =  0.12625\n",
      "DNN's test accuracy on -14 dB SNR samples =  0.131\n",
      "DNN's test accuracy on -12 dB SNR samples =  0.1415\n",
      "DNN's test accuracy on -10 dB SNR samples =  0.192\n",
      "DNN's test accuracy on -8 dB SNR samples =  0.289\n",
      "DNN's test accuracy on -6 dB SNR samples =  0.344\n",
      "DNN's test accuracy on -4 dB SNR samples =  0.39825\n",
      "DNN's test accuracy on -2 dB SNR samples =  0.47975\n",
      "DNN's test accuracy on 0 dB SNR samples =  0.56575\n",
      "DNN's test accuracy on 2 dB SNR samples =  0.69375\n",
      "DNN's test accuracy on 4 dB SNR samples =  0.8105\n",
      "DNN's test accuracy on 6 dB SNR samples =  0.8265\n",
      "DNN's test accuracy on 8 dB SNR samples =  0.82375\n",
      "DNN's test accuracy on 10 dB SNR samples =  0.83675\n",
      "DNN's test accuracy on 12 dB SNR samples =  0.8285\n",
      "DNN's test accuracy on 14 dB SNR samples =  0.828\n",
      "DNN's test accuracy on 16 dB SNR samples =  0.827\n",
      "DNN's test accuracy on 18 dB SNR samples =  0.83325\n"
     ]
    }
   ],
   "source": [
    "for snr in snrs:\n",
    "    print(\"DNN's test accuracy on %d dB SNR samples = \"%(snr), acc_test[snr])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <font color = 'blue'> Visualize DNN's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('classic')\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4), dpi=100)\n",
    "x = snrs\n",
    "y = list(acc_test.values())\n",
    "plt.plot(x, y, marker=\"o\", linewidth=2.0, linestyle='dashed', color='royalblue')\n",
    "plt.axis([-20, 20, 0, 1])\n",
    "plt.xticks(np.arange(min(x), max(x)+1, 2.0))\n",
    "plt.yticks(np.arange(0, 1, 0.10))\n",
    "\n",
    "ttl = plt.title('SNR vs Accuracy', fontsize=16)\n",
    "ttl.set_weight('bold')\n",
    "plt.xlabel('SNR (dB)', fontsize=14)\n",
    "plt.ylabel('Test accuracy', fontsize=14)\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {-20: 0.127,\n",
       "             -18: 0.12675001,\n",
       "             -16: 0.12625,\n",
       "             -14: 0.131,\n",
       "             -12: 0.1415,\n",
       "             -10: 0.192,\n",
       "             -8: 0.289,\n",
       "             -6: 0.34400001,\n",
       "             -4: 0.39825001,\n",
       "             -2: 0.47975001,\n",
       "             0: 0.56575,\n",
       "             2: 0.69375002,\n",
       "             4: 0.81050003,\n",
       "             6: 0.8265,\n",
       "             8: 0.82375002,\n",
       "             10: 0.83674997,\n",
       "             12: 0.82849997,\n",
       "             14: 0.82800001,\n",
       "             16: 0.82700002,\n",
       "             18: 0.83324999})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
