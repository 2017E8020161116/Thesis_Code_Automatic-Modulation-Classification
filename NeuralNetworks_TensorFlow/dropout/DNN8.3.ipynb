{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>  Deep Neural Network (DNN) using plain TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'blue'> Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "X_16_val                  -> array([[-0.05248989,  0.95262376, -0.95081096, ...\n",
      "X_32_val                  -> array([[-0.26412427,  0.80742202,  0.90784197, ...\n",
      "X_32test_std              -> defaultdict(<class 'list'>, {0: array([[-0.2641242\n",
      "X_32train_std             -> array([[-0.71199092,  0.15545522, -0.78672279, ...\n",
      "X_test                    -> defaultdict(<class 'list'>, {0: array([[[ 0.003087\n",
      "X_test_std                -> defaultdict(<class 'list'>, {0: array([[ -5.248988\n",
      "X_train                   -> array([[[ -8.82267195e-04,   4.11425252e-03,  -7.3\n",
      "X_train_std               -> array([[-0.71199092,  0.15545522, -0.78672279, ...\n",
      "snrs                      -> [-20, -18, -16, -14, -12, -10, -8, -6, -4, -2, 0, \n",
      "y_16_val                  -> array([7, 6, 5, ..., 1, 4, 7])\n",
      "y_32_test                 -> defaultdict(<class 'list'>, {0: array([4, 6, 6, ..\n",
      "y_32_train                -> array([4, 2, 0, ..., 1, 4, 6])\n",
      "y_32_val                  -> array([4, 6, 6, ..., 6, 7, 3])\n",
      "y_test                    -> defaultdict(<class 'list'>, {0: array([7, 6, 5, ..\n",
      "y_train                   -> array([4, 2, 0, ..., 1, 4, 6])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import defaultdict\n",
    "from time import time\n",
    "\n",
    "%store -r\n",
    "%store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:  (80000, 32) and labels:  (80000,)\n",
      " \n",
      "Test data:\n",
      "Total 20 (4000, 32) arrays for SNR values:\n",
      "[-20, -18, -16, -14, -12, -10, -8, -6, -4, -2, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data: \", X_32train_std.shape, \"and labels: \", y_32_train.shape)\n",
    "print(\" \")\n",
    "print(\"Test data:\")\n",
    "print(\"Total\", len(X_32test_std), X_32test_std[18].shape, \"arrays for SNR values:\")\n",
    "print(sorted(X_32test_std.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'blue'> Design and train the DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 1.455948\tMinimum loss: 1.455948\tAccuracy on validation set: 0.40\n",
      "1\tValidation loss: 1.359515\tMinimum loss: 1.359515\tAccuracy on validation set: 0.44\n",
      "2\tValidation loss: 1.332091\tMinimum loss: 1.332091\tAccuracy on validation set: 0.45\n",
      "3\tValidation loss: 1.312313\tMinimum loss: 1.312313\tAccuracy on validation set: 0.46\n",
      "4\tValidation loss: 1.302476\tMinimum loss: 1.302476\tAccuracy on validation set: 0.46\n",
      "5\tValidation loss: 1.297685\tMinimum loss: 1.297685\tAccuracy on validation set: 0.46\n",
      "6\tValidation loss: 1.285098\tMinimum loss: 1.285098\tAccuracy on validation set: 0.47\n",
      "7\tValidation loss: 1.267716\tMinimum loss: 1.267716\tAccuracy on validation set: 0.48\n",
      "8\tValidation loss: 1.249361\tMinimum loss: 1.249361\tAccuracy on validation set: 0.49\n",
      "9\tValidation loss: 1.236627\tMinimum loss: 1.236627\tAccuracy on validation set: 0.49\n",
      "10\tValidation loss: 1.224271\tMinimum loss: 1.224271\tAccuracy on validation set: 0.49\n",
      "11\tValidation loss: 1.217040\tMinimum loss: 1.217040\tAccuracy on validation set: 0.50\n",
      "12\tValidation loss: 1.215886\tMinimum loss: 1.215886\tAccuracy on validation set: 0.50\n",
      "13\tValidation loss: 1.200640\tMinimum loss: 1.200640\tAccuracy on validation set: 0.50\n",
      "14\tValidation loss: 1.198620\tMinimum loss: 1.198620\tAccuracy on validation set: 0.50\n",
      "15\tValidation loss: 1.200145\tMinimum loss: 1.198620\tAccuracy on validation set: 0.50\n",
      "16\tValidation loss: 1.192745\tMinimum loss: 1.192745\tAccuracy on validation set: 0.50\n",
      "17\tValidation loss: 1.187997\tMinimum loss: 1.187997\tAccuracy on validation set: 0.50\n",
      "18\tValidation loss: 1.190529\tMinimum loss: 1.187997\tAccuracy on validation set: 0.51\n",
      "19\tValidation loss: 1.187112\tMinimum loss: 1.187112\tAccuracy on validation set: 0.51\n",
      "20\tValidation loss: 1.184943\tMinimum loss: 1.184943\tAccuracy on validation set: 0.51\n",
      "21\tValidation loss: 1.183689\tMinimum loss: 1.183689\tAccuracy on validation set: 0.51\n",
      "22\tValidation loss: 1.181767\tMinimum loss: 1.181767\tAccuracy on validation set: 0.51\n",
      "23\tValidation loss: 1.179680\tMinimum loss: 1.179680\tAccuracy on validation set: 0.51\n",
      "24\tValidation loss: 1.182427\tMinimum loss: 1.179680\tAccuracy on validation set: 0.51\n",
      "25\tValidation loss: 1.180411\tMinimum loss: 1.179680\tAccuracy on validation set: 0.51\n",
      "26\tValidation loss: 1.179508\tMinimum loss: 1.179508\tAccuracy on validation set: 0.51\n",
      "27\tValidation loss: 1.179200\tMinimum loss: 1.179200\tAccuracy on validation set: 0.51\n",
      "28\tValidation loss: 1.176935\tMinimum loss: 1.176935\tAccuracy on validation set: 0.51\n",
      "29\tValidation loss: 1.176355\tMinimum loss: 1.176355\tAccuracy on validation set: 0.51\n",
      "30\tValidation loss: 1.177498\tMinimum loss: 1.176355\tAccuracy on validation set: 0.51\n",
      "31\tValidation loss: 1.176586\tMinimum loss: 1.176355\tAccuracy on validation set: 0.51\n",
      "32\tValidation loss: 1.175340\tMinimum loss: 1.175340\tAccuracy on validation set: 0.51\n",
      "33\tValidation loss: 1.176788\tMinimum loss: 1.175340\tAccuracy on validation set: 0.51\n",
      "34\tValidation loss: 1.177640\tMinimum loss: 1.175340\tAccuracy on validation set: 0.51\n",
      "35\tValidation loss: 1.175721\tMinimum loss: 1.175340\tAccuracy on validation set: 0.51\n",
      "36\tValidation loss: 1.178282\tMinimum loss: 1.175340\tAccuracy on validation set: 0.51\n",
      "37\tValidation loss: 1.175250\tMinimum loss: 1.175250\tAccuracy on validation set: 0.51\n",
      "38\tValidation loss: 1.177608\tMinimum loss: 1.175250\tAccuracy on validation set: 0.51\n",
      "39\tValidation loss: 1.173809\tMinimum loss: 1.173809\tAccuracy on validation set: 0.51\n",
      "40\tValidation loss: 1.174775\tMinimum loss: 1.173809\tAccuracy on validation set: 0.51\n",
      "41\tValidation loss: 1.174342\tMinimum loss: 1.173809\tAccuracy on validation set: 0.51\n",
      "42\tValidation loss: 1.174691\tMinimum loss: 1.173809\tAccuracy on validation set: 0.51\n",
      "43\tValidation loss: 1.171121\tMinimum loss: 1.171121\tAccuracy on validation set: 0.51\n",
      "44\tValidation loss: 1.172602\tMinimum loss: 1.171121\tAccuracy on validation set: 0.51\n",
      "45\tValidation loss: 1.175702\tMinimum loss: 1.171121\tAccuracy on validation set: 0.51\n",
      "46\tValidation loss: 1.173921\tMinimum loss: 1.171121\tAccuracy on validation set: 0.51\n",
      "47\tValidation loss: 1.173699\tMinimum loss: 1.171121\tAccuracy on validation set: 0.51\n",
      "48\tValidation loss: 1.175461\tMinimum loss: 1.171121\tAccuracy on validation set: 0.51\n",
      "49\tValidation loss: 1.174218\tMinimum loss: 1.171121\tAccuracy on validation set: 0.51\n",
      "50\tValidation loss: 1.172534\tMinimum loss: 1.171121\tAccuracy on validation set: 0.51\n",
      "51\tValidation loss: 1.176146\tMinimum loss: 1.171121\tAccuracy on validation set: 0.51\n",
      "52\tValidation loss: 1.173946\tMinimum loss: 1.171121\tAccuracy on validation set: 0.51\n",
      "53\tValidation loss: 1.173653\tMinimum loss: 1.171121\tAccuracy on validation set: 0.51\n",
      "54\tValidation loss: 1.174002\tMinimum loss: 1.171121\tAccuracy on validation set: 0.51\n",
      "55\tValidation loss: 1.177412\tMinimum loss: 1.171121\tAccuracy on validation set: 0.51\n",
      "56\tValidation loss: 1.172510\tMinimum loss: 1.171121\tAccuracy on validation set: 0.51\n",
      "57\tValidation loss: 1.175342\tMinimum loss: 1.171121\tAccuracy on validation set: 0.51\n",
      "58\tValidation loss: 1.176304\tMinimum loss: 1.171121\tAccuracy on validation set: 0.51\n",
      "59\tValidation loss: 1.175530\tMinimum loss: 1.171121\tAccuracy on validation set: 0.51\n",
      "60\tValidation loss: 1.176136\tMinimum loss: 1.171121\tAccuracy on validation set: 0.51\n",
      "61\tValidation loss: 1.174869\tMinimum loss: 1.171121\tAccuracy on validation set: 0.51\n",
      "62\tValidation loss: 1.176375\tMinimum loss: 1.171121\tAccuracy on validation set: 0.51\n",
      "63\tValidation loss: 1.175415\tMinimum loss: 1.171121\tAccuracy on validation set: 0.51\n",
      "** EARLY STOPPING ** \n",
      " \n",
      "INFO:tensorflow:Restoring parameters from ./DNNdropout5.ckpt\n",
      "Training and testing took 8.593389 minutes\n"
     ]
    }
   ],
   "source": [
    "# ----------------- Initialize parameters -----------------------\n",
    "\n",
    "\n",
    "n_hidden1 = 1024\n",
    "n_hidden2 = 1024\n",
    "n_outputs = 8\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, 32))\n",
    "\n",
    "y = tf.placeholder(tf.int64, shape=(None))\n",
    "\n",
    "# ------------------- Define layers -----------------------\n",
    "\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "\n",
    "def layer(X, n_neurons, activation):\n",
    "    layer = fully_connected(X, n_neurons, activation_fn = activation, \n",
    "                            weights_initializer = tf.contrib.layers.xavier_initializer())\n",
    "    dropout_layer = tf.layers.dropout(layer, rate = 0.5, training = True)\n",
    "    return dropout_layer\n",
    "\n",
    "layer1 = layer(X, n_hidden1, activation = tf.nn.relu)\n",
    "\n",
    "layer2 = layer(layer1, n_hidden2, activation = tf.nn.relu)\n",
    "\n",
    "logits = fully_connected(layer2, n_outputs, activation_fn = None, weights_initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "# ----------------- Specify performance measure ----------------------\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        \n",
    "# ------------------ Execution phase ----------------------------------    \n",
    "\n",
    "n_epochs = 1000\n",
    "batch_size = 1024\n",
    "n_train = X_train_std.shape[0]\n",
    "n_iter = n_train//batch_size\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "min_loss = np.infty\n",
    "epochs_without_improvement = 0 \n",
    "max_epochs_without_improvement = 20   \n",
    "\n",
    "acc_test = defaultdict(list)\n",
    "\n",
    "start = time()\n",
    "path = \"./DNNdropout5.ckpt\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(n_iter):\n",
    "            rand_indices = np.random.choice(n_train,batch_size) #select random samples to form mini batches   \n",
    "            X_batch, y_batch = X_32train_std[rand_indices], y_32_train[rand_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        valid_loss, acc_val = sess.run([loss, accuracy], feed_dict={X: X_32_val, y: y_32_val})\n",
    "        \n",
    "        # Early stopping \n",
    "        \n",
    "        if valid_loss < min_loss:\n",
    "            save_path = saver.save(sess, path)\n",
    "            min_loss = valid_loss\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement > max_epochs_without_improvement:\n",
    "                print(\"** EARLY STOPPING ** \")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tMinimum loss: {:.6f}\\tAccuracy on validation set: {:.2f}\".format(\n",
    "            epoch, valid_loss, min_loss, acc_val))\n",
    "\n",
    "print(\" \")\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, path)\n",
    "    for snr in snrs:\n",
    "        acc_test[snr] = accuracy.eval(feed_dict={X: X_32test_std[snr], y: y_32_test[snr]})\n",
    "\n",
    "print(\"Training and testing took %f minutes\"%(float(time() - start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'blue'> Test the DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN's test accuracy on -20 dB SNR samples =  0.12575\n",
      "DNN's test accuracy on -18 dB SNR samples =  0.12325\n",
      "DNN's test accuracy on -16 dB SNR samples =  0.13325\n",
      "DNN's test accuracy on -14 dB SNR samples =  0.126\n",
      "DNN's test accuracy on -12 dB SNR samples =  0.149\n",
      "DNN's test accuracy on -10 dB SNR samples =  0.17725\n",
      "DNN's test accuracy on -8 dB SNR samples =  0.29375\n",
      "DNN's test accuracy on -6 dB SNR samples =  0.3665\n",
      "DNN's test accuracy on -4 dB SNR samples =  0.4095\n",
      "DNN's test accuracy on -2 dB SNR samples =  0.47375\n",
      "DNN's test accuracy on 0 dB SNR samples =  0.559\n",
      "DNN's test accuracy on 2 dB SNR samples =  0.68475\n",
      "DNN's test accuracy on 4 dB SNR samples =  0.80475\n",
      "DNN's test accuracy on 6 dB SNR samples =  0.8245\n",
      "DNN's test accuracy on 8 dB SNR samples =  0.82075\n",
      "DNN's test accuracy on 10 dB SNR samples =  0.831\n",
      "DNN's test accuracy on 12 dB SNR samples =  0.832\n",
      "DNN's test accuracy on 14 dB SNR samples =  0.822\n",
      "DNN's test accuracy on 16 dB SNR samples =  0.826\n",
      "DNN's test accuracy on 18 dB SNR samples =  0.8345\n"
     ]
    }
   ],
   "source": [
    "for snr in snrs:\n",
    "    print(\"DNN's test accuracy on %d dB SNR samples = \"%(snr), acc_test[snr])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <font color = 'blue'> Visualize DNN's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('classic')\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4), dpi=100)\n",
    "x = snrs\n",
    "y = list(acc_test.values())\n",
    "plt.plot(x, y, marker=\"o\", linewidth=2.0, linestyle='dashed', color='royalblue')\n",
    "plt.axis([-20, 20, 0, 1])\n",
    "plt.xticks(np.arange(min(x), max(x)+1, 2.0))\n",
    "plt.yticks(np.arange(0, 1, 0.10))\n",
    "\n",
    "ttl = plt.title('SNR vs Accuracy', fontsize=16)\n",
    "ttl.set_weight('bold')\n",
    "plt.xlabel('SNR (dB)', fontsize=14)\n",
    "plt.ylabel('Test accuracy', fontsize=14)\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {-20: 0.12575001,\n",
       "             -18: 0.12325,\n",
       "             -16: 0.13325,\n",
       "             -14: 0.126,\n",
       "             -12: 0.149,\n",
       "             -10: 0.17725,\n",
       "             -8: 0.29374999,\n",
       "             -6: 0.36649999,\n",
       "             -4: 0.4095,\n",
       "             -2: 0.47375,\n",
       "             0: 0.55900002,\n",
       "             2: 0.68475002,\n",
       "             4: 0.80475003,\n",
       "             6: 0.82450002,\n",
       "             8: 0.82075,\n",
       "             10: 0.83099997,\n",
       "             12: 0.83200002,\n",
       "             14: 0.82200003,\n",
       "             16: 0.82599998,\n",
       "             18: 0.83450001})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
