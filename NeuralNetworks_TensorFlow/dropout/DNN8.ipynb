{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>  Deep Neural Network (DNN) using plain TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'blue'> Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "X_16_val                  -> array([[-0.05248989,  0.95262376, -0.95081096, ...\n",
      "X_32_val                  -> array([[-0.26412427,  0.80742202,  0.90784197, ...\n",
      "X_32test_std              -> defaultdict(<class 'list'>, {0: array([[-0.2641242\n",
      "X_32train_std             -> array([[-0.71199092,  0.15545522, -0.78672279, ...\n",
      "X_test                    -> defaultdict(<class 'list'>, {0: array([[[ 0.003087\n",
      "X_test_std                -> defaultdict(<class 'list'>, {0: array([[ -5.248988\n",
      "X_train                   -> array([[[ -8.82267195e-04,   4.11425252e-03,  -7.3\n",
      "X_train_std               -> array([[-0.71199092,  0.15545522, -0.78672279, ...\n",
      "snrs                      -> [-20, -18, -16, -14, -12, -10, -8, -6, -4, -2, 0, \n",
      "y_16_val                  -> array([7, 6, 5, ..., 1, 4, 7])\n",
      "y_32_test                 -> defaultdict(<class 'list'>, {0: array([4, 6, 6, ..\n",
      "y_32_train                -> array([4, 2, 0, ..., 1, 4, 6])\n",
      "y_32_val                  -> array([4, 6, 6, ..., 6, 7, 3])\n",
      "y_test                    -> defaultdict(<class 'list'>, {0: array([7, 6, 5, ..\n",
      "y_train                   -> array([4, 2, 0, ..., 1, 4, 6])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import defaultdict\n",
    "from time import time\n",
    "\n",
    "%store -r\n",
    "%store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:  (80000, 32) and labels:  (80000,)\n",
      " \n",
      "Test data:\n",
      "Total 20 (4000, 32) arrays for SNR values:\n",
      "[-20, -18, -16, -14, -12, -10, -8, -6, -4, -2, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data: \", X_32train_std.shape, \"and labels: \", y_32_train.shape)\n",
    "print(\" \")\n",
    "print(\"Test data:\")\n",
    "print(\"Total\", len(X_32test_std), X_32test_std[18].shape, \"arrays for SNR values:\")\n",
    "print(sorted(X_32test_std.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'blue'> Design and train the DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 1.384643\tMinimum loss: 1.384643\tAccuracy on validation set: 0.43\n",
      "1\tValidation loss: 1.321580\tMinimum loss: 1.321580\tAccuracy on validation set: 0.45\n",
      "2\tValidation loss: 1.297520\tMinimum loss: 1.297520\tAccuracy on validation set: 0.46\n",
      "3\tValidation loss: 1.275824\tMinimum loss: 1.275824\tAccuracy on validation set: 0.47\n",
      "4\tValidation loss: 1.261870\tMinimum loss: 1.261870\tAccuracy on validation set: 0.48\n",
      "5\tValidation loss: 1.253823\tMinimum loss: 1.253823\tAccuracy on validation set: 0.48\n",
      "6\tValidation loss: 1.221224\tMinimum loss: 1.221224\tAccuracy on validation set: 0.49\n",
      "7\tValidation loss: 1.211397\tMinimum loss: 1.211397\tAccuracy on validation set: 0.50\n",
      "8\tValidation loss: 1.203424\tMinimum loss: 1.203424\tAccuracy on validation set: 0.50\n",
      "9\tValidation loss: 1.196684\tMinimum loss: 1.196684\tAccuracy on validation set: 0.50\n",
      "10\tValidation loss: 1.195107\tMinimum loss: 1.195107\tAccuracy on validation set: 0.50\n",
      "11\tValidation loss: 1.189711\tMinimum loss: 1.189711\tAccuracy on validation set: 0.51\n",
      "12\tValidation loss: 1.176621\tMinimum loss: 1.176621\tAccuracy on validation set: 0.51\n",
      "13\tValidation loss: 1.180700\tMinimum loss: 1.176621\tAccuracy on validation set: 0.51\n",
      "14\tValidation loss: 1.180108\tMinimum loss: 1.176621\tAccuracy on validation set: 0.51\n",
      "15\tValidation loss: 1.173277\tMinimum loss: 1.173277\tAccuracy on validation set: 0.51\n",
      "16\tValidation loss: 1.172432\tMinimum loss: 1.172432\tAccuracy on validation set: 0.51\n",
      "17\tValidation loss: 1.172134\tMinimum loss: 1.172134\tAccuracy on validation set: 0.51\n",
      "18\tValidation loss: 1.169806\tMinimum loss: 1.169806\tAccuracy on validation set: 0.51\n",
      "19\tValidation loss: 1.169955\tMinimum loss: 1.169806\tAccuracy on validation set: 0.51\n",
      "20\tValidation loss: 1.170182\tMinimum loss: 1.169806\tAccuracy on validation set: 0.51\n",
      "21\tValidation loss: 1.170699\tMinimum loss: 1.169806\tAccuracy on validation set: 0.51\n",
      "22\tValidation loss: 1.172393\tMinimum loss: 1.169806\tAccuracy on validation set: 0.51\n",
      "23\tValidation loss: 1.170390\tMinimum loss: 1.169806\tAccuracy on validation set: 0.51\n",
      "24\tValidation loss: 1.168758\tMinimum loss: 1.168758\tAccuracy on validation set: 0.51\n",
      "25\tValidation loss: 1.169106\tMinimum loss: 1.168758\tAccuracy on validation set: 0.51\n",
      "26\tValidation loss: 1.171444\tMinimum loss: 1.168758\tAccuracy on validation set: 0.51\n",
      "27\tValidation loss: 1.170647\tMinimum loss: 1.168758\tAccuracy on validation set: 0.51\n",
      "28\tValidation loss: 1.175277\tMinimum loss: 1.168758\tAccuracy on validation set: 0.51\n",
      "29\tValidation loss: 1.170232\tMinimum loss: 1.168758\tAccuracy on validation set: 0.51\n",
      "30\tValidation loss: 1.174989\tMinimum loss: 1.168758\tAccuracy on validation set: 0.51\n",
      "31\tValidation loss: 1.175485\tMinimum loss: 1.168758\tAccuracy on validation set: 0.51\n",
      "32\tValidation loss: 1.176312\tMinimum loss: 1.168758\tAccuracy on validation set: 0.51\n",
      "33\tValidation loss: 1.179016\tMinimum loss: 1.168758\tAccuracy on validation set: 0.51\n",
      "34\tValidation loss: 1.176769\tMinimum loss: 1.168758\tAccuracy on validation set: 0.51\n",
      "35\tValidation loss: 1.175877\tMinimum loss: 1.168758\tAccuracy on validation set: 0.51\n",
      "36\tValidation loss: 1.180453\tMinimum loss: 1.168758\tAccuracy on validation set: 0.51\n",
      "37\tValidation loss: 1.183948\tMinimum loss: 1.168758\tAccuracy on validation set: 0.51\n",
      "38\tValidation loss: 1.183751\tMinimum loss: 1.168758\tAccuracy on validation set: 0.51\n",
      "39\tValidation loss: 1.181940\tMinimum loss: 1.168758\tAccuracy on validation set: 0.51\n",
      "40\tValidation loss: 1.187502\tMinimum loss: 1.168758\tAccuracy on validation set: 0.51\n",
      "41\tValidation loss: 1.187042\tMinimum loss: 1.168758\tAccuracy on validation set: 0.51\n",
      "42\tValidation loss: 1.191635\tMinimum loss: 1.168758\tAccuracy on validation set: 0.51\n",
      "43\tValidation loss: 1.196150\tMinimum loss: 1.168758\tAccuracy on validation set: 0.51\n",
      "44\tValidation loss: 1.196039\tMinimum loss: 1.168758\tAccuracy on validation set: 0.51\n",
      "** EARLY STOPPING ** \n",
      " \n",
      "INFO:tensorflow:Restoring parameters from ./DNNdropout6.ckpt\n",
      "Training and testing took 6.339213 minutes\n"
     ]
    }
   ],
   "source": [
    "# ----------------- Initialize parameters -----------------------\n",
    "\n",
    "\n",
    "n_hidden1 = 1024\n",
    "n_hidden2 = 1024\n",
    "n_outputs = 8\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, 32))\n",
    "\n",
    "y = tf.placeholder(tf.int64, shape=(None))\n",
    "\n",
    "# ------------------- Define layers -----------------------\n",
    "\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "\n",
    "def layer(X, n_neurons, activation):\n",
    "    layer = fully_connected(X, n_neurons, activation_fn = activation, \n",
    "                            weights_initializer = tf.contrib.layers.xavier_initializer())\n",
    "    dropout_layer = tf.layers.dropout(layer, rate = 0.2, training = True)\n",
    "    return dropout_layer\n",
    "\n",
    "layer1 = layer(X, n_hidden1, activation = tf.nn.relu)\n",
    "\n",
    "layer2 = layer(layer1, n_hidden2, activation = tf.nn.relu)\n",
    "\n",
    "logits = fully_connected(layer2, n_outputs, activation_fn = None, weights_initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "# ----------------- Specify performance measure ----------------------\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        \n",
    "# ------------------ Execution phase ----------------------------------    \n",
    "\n",
    "n_epochs = 1000\n",
    "batch_size = 1024\n",
    "n_train = X_train_std.shape[0]\n",
    "n_iter = n_train//batch_size\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "min_loss = np.infty\n",
    "epochs_without_improvement = 0 \n",
    "max_epochs_without_improvement = 20   \n",
    "\n",
    "acc_test = defaultdict(list)\n",
    "\n",
    "start = time()\n",
    "path = \"./DNNdropout6.ckpt\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(n_iter):\n",
    "            rand_indices = np.random.choice(n_train,batch_size) #select random samples to form mini batches   \n",
    "            X_batch, y_batch = X_32train_std[rand_indices], y_32_train[rand_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        valid_loss, acc_val = sess.run([loss, accuracy], feed_dict={X: X_32_val, y: y_32_val})\n",
    "        \n",
    "        # Early stopping \n",
    "        \n",
    "        if valid_loss < min_loss:\n",
    "            save_path = saver.save(sess, path)\n",
    "            min_loss = valid_loss\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement > max_epochs_without_improvement:\n",
    "                print(\"** EARLY STOPPING ** \")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tMinimum loss: {:.6f}\\tAccuracy on validation set: {:.2f}\".format(\n",
    "            epoch, valid_loss, min_loss, acc_val))\n",
    "\n",
    "print(\" \")\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, path)\n",
    "    for snr in snrs:\n",
    "        acc_test[snr] = accuracy.eval(feed_dict={X: X_32test_std[snr], y: y_32_test[snr]})\n",
    "\n",
    "print(\"Training and testing took %f minutes\"%(float(time() - start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'blue'> Test the DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN's test accuracy on -20 dB SNR samples =  0.12525\n",
      "DNN's test accuracy on -18 dB SNR samples =  0.12825\n",
      "DNN's test accuracy on -16 dB SNR samples =  0.1235\n",
      "DNN's test accuracy on -14 dB SNR samples =  0.131\n",
      "DNN's test accuracy on -12 dB SNR samples =  0.1415\n",
      "DNN's test accuracy on -10 dB SNR samples =  0.18575\n",
      "DNN's test accuracy on -8 dB SNR samples =  0.27675\n",
      "DNN's test accuracy on -6 dB SNR samples =  0.34725\n",
      "DNN's test accuracy on -4 dB SNR samples =  0.40575\n",
      "DNN's test accuracy on -2 dB SNR samples =  0.47925\n",
      "DNN's test accuracy on 0 dB SNR samples =  0.5745\n",
      "DNN's test accuracy on 2 dB SNR samples =  0.69775\n",
      "DNN's test accuracy on 4 dB SNR samples =  0.8025\n",
      "DNN's test accuracy on 6 dB SNR samples =  0.82975\n",
      "DNN's test accuracy on 8 dB SNR samples =  0.82425\n",
      "DNN's test accuracy on 10 dB SNR samples =  0.835\n",
      "DNN's test accuracy on 12 dB SNR samples =  0.83125\n",
      "DNN's test accuracy on 14 dB SNR samples =  0.8305\n",
      "DNN's test accuracy on 16 dB SNR samples =  0.8275\n",
      "DNN's test accuracy on 18 dB SNR samples =  0.83525\n"
     ]
    }
   ],
   "source": [
    "for snr in snrs:\n",
    "    print(\"DNN's test accuracy on %d dB SNR samples = \"%(snr), acc_test[snr])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <font color = 'blue'> Visualize DNN's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('classic')\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4), dpi=100)\n",
    "x = snrs\n",
    "y = list(acc_test.values())\n",
    "plt.plot(x, y, marker=\"o\", linewidth=2.0, linestyle='dashed', color='royalblue')\n",
    "plt.axis([-20, 20, 0, 1])\n",
    "plt.xticks(np.arange(min(x), max(x)+1, 2.0))\n",
    "plt.yticks(np.arange(0, 1, 0.10))\n",
    "\n",
    "ttl = plt.title('SNR vs Accuracy', fontsize=16)\n",
    "ttl.set_weight('bold')\n",
    "plt.xlabel('SNR (dB)', fontsize=14)\n",
    "plt.ylabel('Test accuracy', fontsize=14)\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {-20: 0.12525,\n",
       "             -18: 0.12825,\n",
       "             -16: 0.1235,\n",
       "             -14: 0.131,\n",
       "             -12: 0.1415,\n",
       "             -10: 0.18574999,\n",
       "             -8: 0.27675,\n",
       "             -6: 0.34725001,\n",
       "             -4: 0.40575001,\n",
       "             -2: 0.47925001,\n",
       "             0: 0.57450002,\n",
       "             2: 0.69774997,\n",
       "             4: 0.80250001,\n",
       "             6: 0.82975,\n",
       "             8: 0.82424998,\n",
       "             10: 0.83499998,\n",
       "             12: 0.83125001,\n",
       "             14: 0.83050001,\n",
       "             16: 0.82749999,\n",
       "             18: 0.83525002})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
